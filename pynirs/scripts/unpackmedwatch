#!/usr/bin/env python
import argparse
import json
import struct
import sys

import numpy as np
import pandas as pd


def _get_parser():
    """
    Argument parser for pixelcomp
    """
    parser = argparse.ArgumentParser(
        prog="unpackmedwatch",
        description=(
            "Unpack the data from a medwatch session and output to one text file per sensor"
        ),
        usage="%(prog)s inputfile [options]",
    )

    # Required arguments
    parser.add_argument(
        "inputfile", type=str, help="The name of the medwatch recording."
    )
    parser.add_argument(
        "outputfile", type=str, help="The root name of the output files."
    )

    # add optional arguments
    parser.add_argument(
        "--samplerate",
        action="store",
        type=float,
        metavar="RATE",
        help=("Sample rate in Hz.  Default is 33.0."),
        default=33.0,
    )
    parser.add_argument(
        "--plethfile",
        action="store",
        type=str,
        metavar="NAME",
        help=("Name of an optional output file in plethproc input format."),
        default=None,
    )
    parser.add_argument(
        "--debug",
        dest="debug",
        action="store_true",
        help="Print additional internal information.",
        default=False,
    )
    return parser


def writebidstsv(
    outputfileroot,
    data,
    samplerate,
    compressed=True,
    columns=None,
    starttime=0.0,
    append=False,
    colsinjson=True,
    colsintsv=False,
    omitjson=False,
    debug=False,
):
    """
    NB: to be strictly valid, a continuous BIDS tsv file (i.e. a "_physio" or "_stim" file) requires:
    1) The .tsv is compressed (.tsv.gz)
    2) "SamplingFrequency", "StartTime", "Columns" must exist and be in the .json file
    3) The tsv file does NOT have column headers.
    4) "_physio" or "_stim" has to be at the end of the name, although this seems a little flexible

    The first 3 are the defaults, but if you really want to override them, you can.

    :param outputfileroot:
    :param data:
    :param samplerate:
    :param compressed:
    :param columns:
    :param starttime:
    :param append:
    :param colsinjson:
    :param colsintsv:
    :param omitjson:
    :param debug:
    :return:
    """
    if debug:
        print("entering writebidstsv:")
        print("\toutputfileroot:", outputfileroot)
        print("\tdata.shape:", data.shape)
        print("\tsamplerate:", samplerate)
        print("\tcompressed:", compressed)
        print("\tcolumns:", columns)
        print("\tstarttime:", starttime)
        print("\tappend:", append)
    if len(data.shape) == 1:
        reshapeddata = data.reshape((1, -1))
        if debug:
            print("input data reshaped from", data.shape, "to", reshapeddata.shape)
    else:
        reshapeddata = data

    startcol = 0

    if columns is None:
        columns = []
        for i in range(reshapeddata.shape[0]):
            columns.append(f"col_{str(i + startcol).zfill(2)}")
    else:
        if len(columns) != reshapeddata.shape[0]:
            raise ValueError(
                f"number of column names ({len(columns)}) ",
                f"does not match number of columns ({reshapeddata.shape[1]}) in data",
            )

    df = pd.DataFrame(data=np.transpose(reshapeddata), columns=columns)
    if compressed:
        df.to_csv(
            outputfileroot + ".tsv.gz",
            sep="\t",
            compression="gzip",
            header=colsintsv,
            index=False,
        )
    else:
        df.to_csv(
            outputfileroot + ".tsv",
            sep="\t",
            compression=None,
            header=colsintsv,
            index=False,
        )
    headerdict = {}
    headerdict["SamplingFrequency"] = samplerate
    headerdict["StartTime"] = starttime
    if colsinjson:
        headerdict["Columns"] = columns

    if not omitjson:
        with open(outputfileroot + ".json", "wb") as fp:
            fp.write(
                json.dumps(
                    headerdict, sort_keys=True, indent=4, separators=(",", ":")
                ).encode("utf-8")
            )


def unpackchar(theline, theoffset):
    return struct.unpack("c", theline[theoffset : theoffset + 1])[0]


def unpackshort(theline, theoffset):
    return struct.unpack(">h", theline[theoffset : theoffset + 2])[0]


def unpacklongfrom24bits(theline, theoffset):
    # I think we need to set the high bit in the 4 byte word to be properly centered
    unpackbuf = bytearray([0, 0, 0, 0])
    unpackbuf[1:4] = theline[theoffset : theoffset + 3]
    return struct.unpack(">l", unpackbuf)[0]


def unpack_uint24(theline, theoffset, debug=False):
    """
    Unpack a 24-bit unsigned integer from three bytes of data.

    Args:
        data (bytes): A bytes object containing three bytes of data.

    Returns:
        int: The unpacked 24-bit unsigned integer.
    """
    value = int.from_bytes(
        theline[theoffset : theoffset + 3], byteorder="big", signed=False
    )
    if debug:
        print(
            f"{theline[theoffset]}, {theline[theoffset + 1]}, {theline[theoffset + 2]}: {value}, {value & 0xFFFFFF}"
        )
    return value & 0xFFFFFF


def unpackline(theline, debug=False):
    # theline consists of 29 bytes.  The first two bytes identify the device
    startcharoffset = 0
    sernumoffset = startcharoffset + 1
    idoffset = sernumoffset + 1
    mkroffset = idoffset + 1
    ecgoffset = 5
    bpmoffset = ecgoffset + 8  # 11 -> 12
    spo2offset = bpmoffset + 2  # 13
    ir_rawoffset = spo2offset + 1  # 14
    red_rawoffset = ir_rawoffset + 3  # 17
    acceloffset = red_rawoffset + 3  # 20

    startchar = int(theline[startcharoffset])
    sensor = int(theline[idoffset])
    mkr = int(theline[mkroffset])
    sernum = int(theline[sernumoffset]) - 1

    spo2 = 1.0 * int(theline[spo2offset])

    ecg_1 = 1.0 * unpackshort(theline, ecgoffset)
    ecg_2 = 1.0 * unpackshort(theline, ecgoffset + 2)
    ecg_3 = 1.0 * unpackshort(theline, ecgoffset + 4)

    ir_raw = 1.0 * unpacklongfrom24bits(theline, ir_rawoffset)
    red_raw = 1.0 * unpacklongfrom24bits(theline, red_rawoffset)

    axx = 1.0 * unpackshort(theline, acceloffset)
    axy = 1.0 * unpackshort(theline, acceloffset + 2)
    axz = 1.0 * unpackshort(theline, acceloffset + 4)

    bpm = 1.0 * unpackshort(theline, bpmoffset)
    if debug:
        print(bpm)

    return startchar, sensor, mkr, sernum, [ir_raw, red_raw], [ecg_1, ecg_2, ecg_3], [axx, axy, axz], bpm, spo2


def main():
    # read the arguments
    try:
        args = _get_parser().parse_args()
    except SystemExit:
        _get_parser().print_help()
        raise

    with open(args.inputfile, "rb") as file:
        df = file.read()

    PACKETLEN = 29

    lastloc = 0
    startlocs = []
    markerlocs = []
    for i in range(len(df)):
        if df[i] == 35:
            if i - lastloc == PACKETLEN:
                if args.debug:
                    print("normal packet")
                startlocs.append(i)
                lastloc = i
                markerlocs.append(0)
            elif i - lastloc > PACKETLEN:
                if args.debug:
                    print("marker packet")
                print(i - lastloc)
                startlocs.append(i)
                markerlocs.append(lastloc)
                lastloc = i
                markerlocs.append(1)
            else:
                pass

    # read the file in line by line
    alldata = {}
    numvalidlines = 0
    for idx, startpos in enumerate(startlocs):
        startchar, sensor, mkr, sernum, raw, ecg, accel, bpm, spo2 = unpackline(df[startpos : startpos + PACKETLEN], debug=args.debug)
        if args.debug:
            print(startpos, startchar, sensor, mkr, sernum)
        if startchar != 35:
            print("invalid packet")
        else:
            numvalidlines += 1
            sensornum = str(sensor)
            try:
                dummy = alldata[sensornum]
            except KeyError:
                print(f"initializing {sensornum} {sensor}")
                alldata[sensornum] = {}
                alldata[sensornum]["sensornum"] = sensornum
                alldata[sensornum]["fileline"] = []
                alldata[sensornum]["sernum"] = []
                alldata[sensornum]["mkr"] = []
                alldata[sensornum]["raw"] = []
                alldata[sensornum]["ecg"] = []
                alldata[sensornum]["accel"] = []
                alldata[sensornum]["spo2"] = []
                alldata[sensornum]["bpm"] = []
                alldata[sensornum]["marker"] = []
            alldata[sensornum]["fileline"].append(i)
            alldata[sensornum]["sernum"].append(sernum)
            alldata[sensornum]["mkr"].append(mkr)
            alldata[sensornum]["raw"].append(raw)
            alldata[sensornum]["ecg"].append(ecg)
            alldata[sensornum]["accel"].append(accel)
            alldata[sensornum]["spo2"].append(spo2)
            alldata[sensornum]["bpm"].append(bpm)
            alldata[sensornum]["marker"].append(markerlocs[idx])

    print("data read complete")

    # Figure out the time that each line was recorded - find missing points
    sensorlimits = {}
    maxlen = 0
    for sensornum, sensordict in alldata.items():
        sensorlimits[sensornum] = (
            sensordict["fileline"][0],
            sensordict["fileline"][-1],
        )
        print(
            f"sensor {sensornum} recording begins at line {sensorlimits[sensornum][0]} and ends at line {sensorlimits[sensornum][1]}"
        )
        if len(sensordict["fileline"]) > maxlen:
            maxlen = len(sensordict["fileline"])
            numsensors = np.median(
                np.diff(np.asarray(sensordict["fileline"], dtype=int))
            )
            maxsensor = sensornum

    print(
        f"sensor with most points is {maxsensor} with length {maxlen}.  Number of sensors is {numsensors}"
    )

    # check for serial number errors
    for sensornum, sensordict in alldata.items():
        for i in range(1, len(sensordict["sernum"])):
            if (sensordict["sernum"][i] - sensordict["sernum"][i - 1] + 255) % 255 != 1:
                print(f"serial number anomaly in sensor {sensornum} at timepoint {i}")
                print(f"\t{sensordict['sernum'][i]} does not follow {sensordict['sernum'][i -1]}")


    colnames = [
        "time",
        "sernum",
        "mkr",
        "irraw,",
        "redraw",
        "ecg1",
        "ecg2",
        "ecg3",
        "axx",
        "axy",
        "axz",
        "spo2",
        "bpm",
    ]
    for sensornum, sensordict in alldata.items():
        numdatapoints = len(sensordict["raw"])
        print(f"sensor {sensornum} has {numdatapoints} items")
        outputdata = np.zeros((numdatapoints, 13), dtype=float)
        colloc = 0
        colsz = 1
        outputdata[:, colloc] = (
            np.linspace(0, numdatapoints, numdatapoints, endpoint=False)
            / args.samplerate
        )
        colloc += colsz
        colsz = 1
        outputdata[:, colloc] = np.asarray(sensordict["sernum"], dtype=int)
        colloc += colsz
        colsz = 1
        outputdata[:, colloc] = np.asarray(sensordict["mkr"], dtype=int)
        colloc += colsz
        colsz = 2
        outputdata[:, colloc:colloc + colsz] = np.asarray(sensordict["raw"], dtype=float)
        colloc += colsz
        colsz = 3
        outputdata[:, colloc:colloc + colsz] = np.asarray(sensordict["ecg"], dtype=float)
        colloc += colsz
        colsz = 3
        outputdata[:, colloc:colloc + colsz] = np.asarray(sensordict["accel"], dtype=float)
        colloc += colsz
        colsz = 1
        outputdata[:, colloc] = np.asarray(sensordict["spo2"], dtype=float)
        colloc += colsz
        colsz = 1
        outputdata[:, colloc] = np.asarray(sensordict["bpm"], dtype=float)
        writebidstsv(
            f"{args.outputfile}_{sensornum}",
            np.transpose(outputdata),
            args.samplerate,
            columns=colnames,
        )

    for sensornum, sensordict in alldata.items():
        d = {}
        # print("Start Time: 09:45:47.545000")
        # print(f"Sample Rate: {samplerate}Hz")
        # print(f"Used LFO Channel Number: CH{sensornum}")
        # print("IR:infrared, VS:visible(red), E:External Marker, B:Button Marker, T:Toggle Marker, S:Synchronous Marker, C:Calibrate Marker")
        cols = [
            "Time",
            "CH1-IR",
            "CH1-VS",
            "ACC_X",
            "ACC_Y",
            "ACC_Z",
            "TTL-IN",
            "TTL-OUT",
            "ADC1",
            "ADC2",
            "DAC",
            "E",
            "B",
            "T",
            "S",
            "C",
        ]
        numdatapoints = len(sensordict["raw"])
        print(f"sensor {sensornum} has {numdatapoints} items")
        timeaxis = np.linspace(0, numdatapoints, numdatapoints, endpoint=False) / args.samplerate
        d["Time"] = timeaxis
        d["CH1-IR"] = np.asarray(sensordict["raw"], dtype=float)[:, 0]
        d["CH1-VS"] = np.asarray(sensordict["raw"], dtype=float)[:, 1]

        d["ACC_X"] = np.asarray(sensordict["accel"], dtype=float)[:, 0]
        d["ACC_Y"] = np.asarray(sensordict["accel"], dtype=float)[:, 1]
        d["ACC_Z"] = np.asarray(sensordict["accel"], dtype=float)[:, 2]

        d["TTL-IN"] = np.zeros(numdatapoints, dtype=float)
        d["TTL-OUT"] = np.zeros(numdatapoints, dtype=float)
        d["ADC1"] = np.zeros(numdatapoints, dtype=float)
        d["ADC2"] = np.zeros(numdatapoints, dtype=float)
        d["DAC"] = np.zeros(numdatapoints, dtype=float)
        d["E"] = np.zeros(numdatapoints, dtype=float)
        markerarray= np.asarray(sensordict["marker"], dtype=float)
        d["B"] = markerarray
        d["T"] = np.zeros(numdatapoints, dtype=float)
        d["S"] = np.zeros(numdatapoints, dtype=float)
        d["C"] = np.zeros(numdatapoints, dtype=float)
        print(f"Sensor {sensornum} has markers at {timeaxis[np.where(markerarray == 1)]}")

        df = pd.DataFrame(data=d)
        df = df[cols]
        df.to_csv(f"{args.plethfile}_{sensornum}.txt", sep="\t", index=False)


if __name__ == "__main__":
    main()
