#!/usr/bin/env python
import argparse
import json
import struct

import numpy as np
import pandas as pd


def _get_parser():
    """
    Argument parser for pixelcomp
    """
    parser = argparse.ArgumentParser(
        prog="unpackmedwatch",
        description=(
            "Unpack the data from a medwatch session and output to one text file per sensor"
        ),
        usage="%(prog)s inputfile [options]",
    )

    # Required arguments
    parser.add_argument(
        "inputfile", type=str, help="The name of the medwatch recording."
    )
    parser.add_argument(
        "outputfile", type=str, help="The root name of the output files."
    )

    # add optional arguments
    parser.add_argument(
        "--samplerate",
        action="store",
        type=float,
        metavar="RATE",
        help=("Sample rate in Hz.  Default is 33.0."),
        default=33.0,
    )
    parser.add_argument(
        "--plethfile",
        action="store",
        type=str,
        metavar="NAME",
        help=("Name of an optional output file in plethproc input format."),
        default=None,
    )
    return parser


def writebidstsv(
    outputfileroot,
    data,
    samplerate,
    compressed=True,
    columns=None,
    starttime=0.0,
    append=False,
    colsinjson=True,
    colsintsv=False,
    omitjson=False,
    debug=False,
):
    """
    NB: to be strictly valid, a continuous BIDS tsv file (i.e. a "_physio" or "_stim" file) requires:
    1) The .tsv is compressed (.tsv.gz)
    2) "SamplingFrequency", "StartTime", "Columns" must exist and be in the .json file
    3) The tsv file does NOT have column headers.
    4) "_physio" or "_stim" has to be at the end of the name, although this seems a little flexible

    The first 3 are the defaults, but if you really want to override them, you can.

    :param outputfileroot:
    :param data:
    :param samplerate:
    :param compressed:
    :param columns:
    :param starttime:
    :param append:
    :param colsinjson:
    :param colsintsv:
    :param omitjson:
    :param debug:
    :return:
    """
    if debug:
        print("entering writebidstsv:")
        print("\toutputfileroot:", outputfileroot)
        print("\tdata.shape:", data.shape)
        print("\tsamplerate:", samplerate)
        print("\tcompressed:", compressed)
        print("\tcolumns:", columns)
        print("\tstarttime:", starttime)
        print("\tappend:", append)
    if len(data.shape) == 1:
        reshapeddata = data.reshape((1, -1))
        if debug:
            print("input data reshaped from", data.shape, "to", reshapeddata.shape)
    else:
        reshapeddata = data

    startcol = 0

    if columns is None:
        columns = []
        for i in range(reshapeddata.shape[0]):
            columns.append(f"col_{str(i + startcol).zfill(2)}")
    else:
        if len(columns) != reshapeddata.shape[0]:
            raise ValueError(
                f"number of column names ({len(columns)}) ",
                f"does not match number of columns ({reshapeddata.shape[1]}) in data",
            )

    df = pd.DataFrame(data=np.transpose(reshapeddata), columns=columns)
    if compressed:
        df.to_csv(
            outputfileroot + ".tsv.gz",
            sep="\t",
            compression="gzip",
            header=colsintsv,
            index=False,
        )
    else:
        df.to_csv(
            outputfileroot + ".tsv",
            sep="\t",
            compression=None,
            header=colsintsv,
            index=False,
        )
    headerdict = {}
    headerdict["SamplingFrequency"] = samplerate
    headerdict["StartTime"] = starttime
    if colsinjson:
        headerdict["Columns"] = columns

    if not omitjson:
        with open(outputfileroot + ".json", "wb") as fp:
            fp.write(
                json.dumps(
                    headerdict, sort_keys=True, indent=4, separators=(",", ":")
                ).encode("utf-8")
            )


def unpackchar(theline, theoffset):
    return struct.unpack("c", theline[theoffset : theoffset + 1])[0]


def unpackshort(theline, theoffset):
    return struct.unpack(">h", theline[theoffset : theoffset + 2])[0]


def unpacklongfrom24bits(theline, theoffset):
    # I think we need to set the high bit in the 4 byte word to be properly centered
    unpackbuf = bytearray([128, 0, 0, 0])
    unpackbuf[1:4] = theline[theoffset : theoffset + 3]
    return struct.unpack(">l", unpackbuf)[0]


def unpack_uint24(theline, theoffset, debug=False):
    """
    Unpack a 24-bit unsigned integer from three bytes of data.

    Args:
        data (bytes): A bytes object containing three bytes of data.

    Returns:
        int: The unpacked 24-bit unsigned integer.
    """
    value = int.from_bytes(
        theline[theoffset : theoffset + 3], byteorder="big", signed=False
    )
    if debug:
        print(
            f"{theline[theoffset]}, {theline[theoffset + 1]}, {theline[theoffset + 2]}: {value}, {value & 0xFFFFFF}"
        )
    return value & 0xFFFFFF


def unpackline(theline):
    # theline consists of 27 bytes.  The first two bytes identify the device
    id = theline[0:2]
    spo2offset = 13
    ecgoffset = 3
    ir_rawoffset = 14
    red_rawoffset = 17
    acceloffset = 20
    bpmoffset = 11

    spo2 = 1.0 * int(theline[spo2offset])

    ecg_1 = 1.0 * unpackshort(theline, ecgoffset)
    ecg_2 = 1.0 * unpackshort(theline, ecgoffset + 2)
    ecg_3 = 1.0 * unpackshort(theline, ecgoffset + 4)

    ir_raw = 1.0 * unpacklongfrom24bits(theline, ir_rawoffset)
    red_raw = 1.0 * unpacklongfrom24bits(theline, red_rawoffset)

    axx = 1.0 * unpackshort(theline, acceloffset)
    axy = 1.0 * unpackshort(theline, acceloffset + 2)
    axz = 1.0 * unpackshort(theline, acceloffset + 4)

    bpm = 1.0 * unpackshort(theline, bpmoffset)

    return id, [ir_raw, red_raw], [ecg_1, ecg_2, ecg_3], [axx, axy, axz], bpm, spo2


def main():
    # read the arguments
    try:
        args = _get_parser().parse_args()
    except SystemExit:
        _get_parser().print_help()
        raise

    with open(args.inputfile, "rb") as file:
        df = file.read()

    numlines = int(len(df) / 27)

    # read the file in line by line
    alldata = {}
    numvalidlines = 0
    for i in range(numlines):
        startpos = i * 27
        id, raw, ecg, accel, bpm, spo2 = unpackline(df[startpos : startpos + 27])
        if id[0] != 35:
            print("invalid packet")
        else:
            numvalidlines += 1
            sensornum = str(id[1])
            try:
                dummy = alldata[sensornum]
            except KeyError:
                print(f"initializing {sensornum} {id[1]}")
                alldata[sensornum] = {}
                alldata[sensornum]["sensornum"] = sensornum
                alldata[sensornum]["fileline"] = []
                alldata[sensornum]["raw"] = []
                alldata[sensornum]["ecg"] = []
                alldata[sensornum]["accel"] = []
                alldata[sensornum]["spo2"] = []
                alldata[sensornum]["bpm"] = []
            alldata[sensornum]["fileline"].append(i)
            alldata[sensornum]["raw"].append(raw)
            alldata[sensornum]["ecg"].append(ecg)
            alldata[sensornum]["accel"].append(accel)
            alldata[sensornum]["spo2"].append(spo2)
            alldata[sensornum]["bpm"].append(bpm)
    print("data read complete")

    # Figure out the time that each line was recorded - find missing points
    sensorlimits = {}
    maxlen = 0
    for sensornum, sensordict in alldata.items():
        sensorlimits[sensornum] = (
            sensordict["fileline"][0],
            sensordict["fileline"][-1],
        )
        print(
            f"sensor {sensornum} recording begins at line {sensorlimits[sensornum][0]} and ends at line {sensorlimits[sensornum][1]}"
        )
        if len(sensordict["fileline"]) > maxlen:
            maxlen = len(sensordict["fileline"])
            numsensors = np.median(
                np.diff(np.asarray(sensordict["fileline"], dtype=int))
            )
            maxsensor = sensornum

    print(
        f"sensor with most points is {maxsensor} with length {maxlen}.  Number of sensors is {numsensors}"
    )

    colnames = [
        "time",
        "irraw,",
        "redraw",
        "ecg1",
        "ecg2",
        "ecg3",
        "axx",
        "axy",
        "axz",
        "spo2",
        "bpm",
    ]
    for sensornum, sensordict in alldata.items():
        numdatapoints = len(sensordict["raw"])
        print(f"sensor {sensornum} has {numdatapoints} items")
        outputdata = np.zeros((numdatapoints, 11), dtype=float)
        outputdata[:, 0] = (
            np.linspace(0, numdatapoints, numdatapoints, endpoint=False)
            / args.samplerate
        )
        outputdata[:, 1:3] = np.asarray(sensordict["raw"], dtype=float)
        outputdata[:, 3:6] = np.asarray(sensordict["ecg"], dtype=float)
        outputdata[:, 6:9] = np.asarray(sensordict["accel"], dtype=float)
        outputdata[:, 9] = np.asarray(sensordict["spo2"], dtype=float)
        outputdata[:, 10] = np.asarray(sensordict["bpm"], dtype=float)
        writebidstsv(
            f"{args.outputfile}_{sensornum}",
            np.transpose(outputdata),
            args.samplerate,
            columns=colnames,
        )

    for sensornum, sensordict in alldata.items():
        d = {}
        # print("Start Time: 09:45:47.545000")
        # print(f"Sample Rate: {samplerate}Hz")
        # print(f"Used LFO Channel Number: CH{sensornum}")
        # print("IR:infrared, VS:visible(red), E:External Marker, B:Button Marker, T:Toggle Marker, S:Synchronous Marker, C:Calibrate Marker")
        cols = [
            "Time",
            "CH1-IR",
            "CH1-VS",
            "ACC_X",
            "ACC_Y",
            "ACC_Z",
            "TTL-IN",
            "TTL-OUT",
            "ADC1",
            "ADC2",
            "DAC",
            "E",
            "B",
            "T",
            "S",
            "C",
        ]
        numdatapoints = len(sensordict["raw"])
        print(f"sensor {sensornum} has {numdatapoints} items")
        d["Time"] = (
            np.linspace(0, numdatapoints, numdatapoints, endpoint=False)
            / args.samplerate
        )
        d["CH1-IR"] = np.asarray(sensordict["raw"], dtype=float)[:, 0]
        d["CH1-VS"] = np.asarray(sensordict["raw"], dtype=float)[:, 1]

        d["ACC_X"] = np.asarray(sensordict["accel"], dtype=float)[:, 0]
        d["ACC_Y"] = np.asarray(sensordict["accel"], dtype=float)[:, 1]
        d["ACC_Z"] = np.asarray(sensordict["accel"], dtype=float)[:, 2]

        d["TTL-IN"] = np.zeros(numdatapoints, dtype=float)
        d["TTL-OUT"] = np.zeros(numdatapoints, dtype=float)
        d["ADC1"] = np.zeros(numdatapoints, dtype=float)
        d["ADC2"] = np.zeros(numdatapoints, dtype=float)
        d["DAC"] = np.zeros(numdatapoints, dtype=float)
        d["E"] = np.zeros(numdatapoints, dtype=float)
        d["B"] = np.zeros(numdatapoints, dtype=float)
        d["T"] = np.zeros(numdatapoints, dtype=float)
        d["S"] = np.zeros(numdatapoints, dtype=float)
        d["C"] = np.zeros(numdatapoints, dtype=float)

        df = pd.DataFrame(data=d)
        df = df[cols]
        df.to_csv(f"{args.plethfile}_{sensornum}.txt", sep="\t", index=False)


if __name__ == "__main__":
    main()
